python robocasa/scripts/collect_demos.py --env CoffeeServeMug --device spacemouse --camera robot0_agentview_left --pos-sensitivity 2.0 --rot-sensitivity 2.0
 OMP_NUM_THREADS=1 MPI_NUM_THREADS=1 MKL_NUM_THREADS=1 OPENBLAS_NUM_THREADS=1 python robocasa/scripts/dataset_states_to_obs.py --dataset /home/michellezhao/robocasa_dagger/robocasa/robocasa/models/assets/demonstrations_private/2025-07-10-12-10-55/demo.hdf5 

OMP_NUM_THREADS=1 MPI_NUM_THREADS=1 MKL_NUM_THREADS=1 OPENBLAS_NUM_THREADS=1 python ../robocasa/robocasa/scripts/original_robocasa_dataset_states_to_obs.py --dataset ../robocasa/datasets_first/v0.1/single_stage/kitchen_coffee/CoffeeServeMug/2024-05-01/demo_gentex_im128_randcams.hdf5
CUDA_VISIBLE_DEVICES=2 HYDRA_FULL_ERROR=1 python train.py --config-dir=. --config-name=train_robocasa_base_dp_clip_policy.yaml training.seed=42 task.name='CoffeeServeMug' experiment_tag='RedoDemos_ST_DAgger'


While an ideal DAgger continual learning system would simply run through a single script, 
the long training times of diffusion policy and other imitation learning policies on an
increasingly large set of demonstrations makes having a single script less than ideal for debugging.

DAgger is thus run through a series of scripts.

$ conda activate robocasa_diffusion_policy_umi

0. Choose Task: CoffeePressButton
CoffeePressButton: kitchen_coffee/CoffeePressButton/2024-04-25 

1. Replay the Robocasa dataset for your task to get 256x256 image observations, rather than 128x128.
$ OMP_NUM_THREADS=1 MPI_NUM_THREADS=1 MKL_NUM_THREADS=1 OPENBLAS_NUM_THREADS=1 python ../robocasa/robocasa/scripts/original_robocasa_dataset_states_to_obs.py --dataset ../robocasa/datasets_first/v0.1/single_stage/kitchen_coffee/CoffeePressButton/2024-04-25/demo_gentex_im128_randcams.hdf5

2. Training a base policy: (horizon 1)
This requires the base workspace to be the default UMI DP workspace:
train_diffusion_unet_clip_workspace.TrainDiffusionUnetImageWorkspace. Finetuning will have its own.

CUDA_VISIBLE_DEVICES=0 HYDRA_FULL_ERROR=1 python train.py --config-dir=. --config-name=train_robocasa_base_dp_clip_policy.yaml training.seed=42 task.name='CoffeePressButton'




3. Evaluate your base policy - You can skip this step as it can be merged with Step 6
CUDA_VISIBLE_DEVICES=0 python evaluate.py --config-name=eval_robocasa_base_policy task_name='CoffeePressButton'



4. Get obs encodings fpr FAIL-Detect
CUDA_VISIBLE_DEVICES=0 python get_demo_obs_encodings.py --config-name=get_obs_embeds_robocasa task_name='CoffeePressButton'



5. Train FAIL-Detect Score Networks
CUDA_VISIBLE_DEVICES=0 python train_fail_detect.py --config-name=train_fd_score_network_robocasa task.name='CoffeePressButton'



6. Use Score Networks to get observation scores on rollouts
CUDA_VISIBLE_DEVICES=0 python score_rollouts.py --config-name=compute_fd_rollout_scores_robocasa task_name='CoffeePressButton'


7. Construct CP band from scores. This will use the constant time band
python get_band_from_scores_multitask.py CoffeePressButton


7. Run DAgger Round 1
HYDRA_FULL_ERROR=1 MUJOCO_GL=egl python dagger_interactive_rollout.py --config-name=run_faildetect_dagger_robocasa task_name='CoffeePressButton'


8. Merge datafiles
python merge_dagger_datasets.py --task_name CoffeePressButton --dataset1 train --dataset2 dagger_episode_0

9. Retraining with Options

A. Finetuning on a Single Dataset file
CUDA_VISIBLE_DEVICES=0 HYDRA_FULL_ERROR=1 python finetune.py --config-dir=. --config-name=finetune_after_dagger_robocasa.yaml training.seed=42 task.name='CoffeePressButton' finetuning.dagger_episode_folder='dagger_episode_0' finetuning.human_only=True finetuning.from_scratch=False
CUDA_VISIBLE_DEVICES=1 HYDRA_FULL_ERROR=1 python finetune.py --config-dir=. --config-name=finetune_after_dagger_robocasa.yaml training.seed=42 task.name='CoffeePressButton' finetuning.dagger_episode_folder='dagger_episode_0' finetuning.human_only=False finetuning.from_scratch=False
CUDA_VISIBLE_DEVICES=2 HYDRA_FULL_ERROR=1 python finetune.py --config-dir=. --config-name=finetune_after_dagger_robocasa.yaml training.seed=42 task.name='CoffeePressButton' finetuning.dagger_episode_folder='dagger_episode_0' finetuning.human_only=False finetuning.from_scratch=True


B. Finetuning with batch balancing


