While an ideal DAgger continual learning system would simply run through a single script, 
the long training times of diffusion policy and other imitation learning policies on an
increasingly large set of demonstrations makes having a single script less than ideal for debugging.

DAgger is thus run through a series of scripts.

$ conda activate robocasa_diffusion_policy_umi

0. Choose Task:
PnPSinkToCounter: kitchen_pnp/PnPSinkToCounter/2024-04-26_2 
OpenSingleDoor: kitchen_doors/OpenSingleDoor/2024-04-24 
OpenDrawer: kitchen_drawer/OpenDrawer/2024-05-03 
TurnOnStove: kitchen_stove/TurnOnStove/2024-05-02
TurnOnSinkFaucet: kitchen_sink/TurnOnSinkFaucet/2024-04-25 
CoffeePressButton: kitchen_coffee/CoffeePressButton/2024-04-25 
CoffeeServeMug: kitchen_coffee/CoffeeServeMug/2024-05-01

1. Replay the Robocasa dataset for your task to get 256x256 image observations, rather than 128x128.
$ OMP_NUM_THREADS=1 MPI_NUM_THREADS=1 MKL_NUM_THREADS=1 OPENBLAS_NUM_THREADS=1 python ../robocasa/robocasa/scripts/original_robocasa_dataset_states_to_obs.py --dataset ../robocasa/datasets_first/v0.1/single_stage/{dataset filepath}/demo_gentex_im128_randcams.hdf5

For the above tasks
$ OMP_NUM_THREADS=1 MPI_NUM_THREADS=1 MKL_NUM_THREADS=1 OPENBLAS_NUM_THREADS=1 python ../robocasa/robocasa/scripts/original_robocasa_dataset_states_to_obs.py --dataset ../robocasa/datasets_first/v0.1/single_stage/kitchen_doors/OpenSingleDoor/2024-04-24/demo_gentex_im128_randcams.hdf5
$ OMP_NUM_THREADS=1 MPI_NUM_THREADS=1 MKL_NUM_THREADS=1 OPENBLAS_NUM_THREADS=1 python ../robocasa/robocasa/scripts/original_robocasa_dataset_states_to_obs.py --dataset ../robocasa/datasets_first/v0.1/single_stage/kitchen_drawer/OpenDrawer/2024-05-03/demo_gentex_im128_randcams.hdf5
$ OMP_NUM_THREADS=1 MPI_NUM_THREADS=1 MKL_NUM_THREADS=1 OPENBLAS_NUM_THREADS=1 python ../robocasa/robocasa/scripts/original_robocasa_dataset_states_to_obs.py --dataset ../robocasa/datasets_first/v0.1/single_stage/kitchen_stove/TurnOnStove/2024-05-02/demo_gentex_im128_randcams.hdf5
$ OMP_NUM_THREADS=1 MPI_NUM_THREADS=1 MKL_NUM_THREADS=1 OPENBLAS_NUM_THREADS=1 python ../robocasa/robocasa/scripts/original_robocasa_dataset_states_to_obs.py --dataset ../robocasa/datasets_first/v0.1/single_stage/kitchen_sink/TurnOnSinkFaucet/2024-04-25/demo_gentex_im128_randcams.hdf5
$ OMP_NUM_THREADS=1 MPI_NUM_THREADS=1 MKL_NUM_THREADS=1 OPENBLAS_NUM_THREADS=1 python ../robocasa/robocasa/scripts/original_robocasa_dataset_states_to_obs.py --dataset ../robocasa/datasets_first/v0.1/single_stage/kitchen_coffee/CoffeePressButton/2024-04-25/demo_gentex_im128_randcams.hdf5
$ OMP_NUM_THREADS=1 MPI_NUM_THREADS=1 MKL_NUM_THREADS=1 OPENBLAS_NUM_THREADS=1 python ../robocasa/robocasa/scripts/original_robocasa_dataset_states_to_obs.py --dataset ../robocasa/datasets_first/v0.1/single_stage/kitchen_coffee/CoffeeServeMug/2024-05-01/demo_gentex_im128_randcams.hdf5


2. Training a base policy: (horizon 1)
This requires the base workspace to be the default UMI DP workspace:
train_diffusion_unet_clip_workspace.TrainDiffusionUnetImageWorkspace. Finetuning will have its own.


CUDA_VISIBLE_DEVICES=1 HYDRA_FULL_ERROR=1 
python train.py --config-dir=. --config-name=train_robocasa_base_dp_clip_policy.yaml training.seed=42 task.name='PnPSinkToCounter'

CUDA_VISIBLE_DEVICES=0 HYDRA_FULL_ERROR=1 python train.py --config-dir=. --config-name=train_robocasa_base_dp_clip_policy.yaml training.seed=42 task.name='OpenSingleDoor'
CUDA_VISIBLE_DEVICES=2 HYDRA_FULL_ERROR=1 python train.py --config-dir=. --config-name=train_robocasa_base_dp_clip_policy.yaml training.seed=42 task.name='CoffeeServeMug'

# second half
CUDA_VISIBLE_DEVICES=0 HYDRA_FULL_ERROR=1 python train.py --config-dir=. --config-name=train_robocasa_base_dp_clip_policy.yaml training.seed=42 task.name='TurnOnStove'
CUDA_VISIBLE_DEVICES=1 HYDRA_FULL_ERROR=1 python train.py --config-dir=. --config-name=train_robocasa_base_dp_clip_policy.yaml training.seed=42 task.name='TurnOnSinkFaucet'
CUDA_VISIBLE_DEVICES=2 HYDRA_FULL_ERROR=1 python train.py --config-dir=. --config-name=train_robocasa_base_dp_clip_policy.yaml training.seed=42 task.name='CoffeePressButton'




3. Evaluate your base policy - can merge this step with 6
CUDA_VISIBLE_DEVICES=2 python evaluate.py --config-name=eval_robocasa_base_policy task_name='OpenSingleDoor'
CUDA_VISIBLE_DEVICES=1 python evaluate.py --config-name=eval_robocasa_base_policy task_name='CoffeeServeMug'
CUDA_VISIBLE_DEVICES=0 python evaluate.py --config-name=eval_robocasa_base_policy task_name='PnPSinkToCounter'


Because of the rendering issue, I'm considering a much more onscreen, but slower approach.
CUDA_VISIBLE_DEVICES=0 python evaluate.py --config-name=onscreen_eval_robocasa_base_policy task_name='OpenSingleDoor'
CUDA_VISIBLE_DEVICES=1 python evaluate.py --config-name=onscreen_eval_robocasa_base_policy task_name='CoffeeServeMug'
CUDA_VISIBLE_DEVICES=2 python evaluate.py --config-name=onscreen_eval_robocasa_base_policy task_name='PnPSinkToCounter'




4. Get obs encodings fpr FAIL-Detect
CUDA_VISIBLE_DEVICES=0 python get_demo_obs_encodings.py --config-name=get_obs_embeds_robocasa task_name='OpenSingleDoor'
CUDA_VISIBLE_DEVICES=1 python get_demo_obs_encodings.py --config-name=get_obs_embeds_robocasa task_name='CoffeeServeMug'
CUDA_VISIBLE_DEVICES=2 python get_demo_obs_encodings.py --config-name=get_obs_embeds_robocasa task_name='PnPSinkToCounter'
CUDA_VISIBLE_DEVICES=0 python get_demo_obs_encodings.py --config-name=get_obs_embeds_robocasa task_name='TurnOnStove'
CUDA_VISIBLE_DEVICES=1 python get_demo_obs_encodings.py --config-name=get_obs_embeds_robocasa task_name='TurnOnSinkFaucet'
CUDA_VISIBLE_DEVICES=2 python get_demo_obs_encodings.py --config-name=get_obs_embeds_robocasa task_name='CoffeePressButton'



5. Train FAIL-Detect Score Networks
CUDA_VISIBLE_DEVICES=0 python train_fail_detect.py --config-name=train_fd_score_network_robocasa task.name='OpenSingleDoor'
CUDA_VISIBLE_DEVICES=1 python train_fail_detect.py --config-name=train_fd_score_network_robocasa task.name='CoffeeServeMug'
CUDA_VISIBLE_DEVICES=2 python train_fail_detect.py --config-name=train_fd_score_network_robocasa task.name='PnPSinkToCounter'
CUDA_VISIBLE_DEVICES=0 python train_fail_detect.py --config-name=train_fd_score_network_robocasa task.name='TurnOnStove'
CUDA_VISIBLE_DEVICES=1 python train_fail_detect.py --config-name=train_fd_score_network_robocasa task.name='TurnOnSinkFaucet'
CUDA_VISIBLE_DEVICES=2 python train_fail_detect.py --config-name=train_fd_score_network_robocasa task.name='CoffeePressButton'



6. Use Score Networks to get observation scores on rollouts
CUDA_VISIBLE_DEVICES=0 python score_rollouts.py --config-name=compute_fd_rollout_scores_robocasa task_name='OpenSingleDoor'
CUDA_VISIBLE_DEVICES=1 python score_rollouts.py --config-name=compute_fd_rollout_scores_robocasa task_name='CoffeeServeMug'
CUDA_VISIBLE_DEVICES=2 python score_rollouts.py --config-name=compute_fd_rollout_scores_robocasa task_name='PnPSinkToCounter'
CUDA_VISIBLE_DEVICES=0 python score_rollouts.py --config-name=compute_fd_rollout_scores_robocasa task_name='TurnOnStove'
CUDA_VISIBLE_DEVICES=1 python score_rollouts.py --config-name=compute_fd_rollout_scores_robocasa task_name='TurnOnSinkFaucet'
CUDA_VISIBLE_DEVICES=2 python score_rollouts.py --config-name=compute_fd_rollout_scores_robocasa task_name='CoffeePressButton'

TODO: make this flag the constant or time varying band
7. Construct CP band from scores
python get_band_from_scores_multitask.py OpenSingleDoor
python get_band_from_scores_multitask.py CoffeeServeMug
python get_band_from_scores_multitask.py PnPSinkToCounter
python get_band_from_scores_multitask.py TurnOnStove
python get_band_from_scores_multitask.py TurnOnSinkFaucet
python get_band_from_scores_multitask.py CoffeePressButton


7. Run DAgger Round 1
HYDRA_FULL_ERROR=1 MUJOCO_GL=egl python dagger_interactive_rollout.py --config-name=run_faildetect_dagger_robocasa task_name='OpenSingleDoor'
HYDRA_FULL_ERROR=1 MUJOCO_GL=egl python dagger_interactive_rollout.py --config-name=run_faildetect_dagger_robocasa task_name='CoffeePressButton'
HYDRA_FULL_ERROR=1 MUJOCO_GL=egl python dagger_interactive_rollout.py --config-name=run_faildetect_dagger_robocasa task_name='PnPSinkToCounter'

Might want thism, but Don't need this anymore
OMP_NUM_THREADS=1 MPI_NUM_THREADS=1 MKL_NUM_THREADS=1 OPENBLAS_NUM_THREADS=1 python ../robocasa/robocasa/scripts/dataset_states_to_obs.py --dataset data/outputs/ST_OOD_DAgger_train_diffusion_unet_clip_CoffeePressButton/dagger_episode_0/processed_dagger_data/human_only_demo.hdf5
OMP_NUM_THREADS=1 MPI_NUM_THREADS=1 MKL_NUM_THREADS=1 OPENBLAS_NUM_THREADS=1 python ../robocasa/robocasa/scripts/dataset_states_to_obs.py --dataset data/outputs/ST_OOD_DAgger_train_diffusion_unet_clip_CoffeePressButton/dagger_episode_0/processed_dagger_data/combined_demo.hdf5



8. Merge datafiles
python merge_dagger_datasets.py --task_name CoffeePressButton --dataset1 train --dataset2 dagger_episode_0

9. Retraining

SECTION 1. Finetuning on a Single Dataset file
Dont bother with human-only: CUDA_VISIBLE_DEVICES=0 HYDRA_FULL_ERROR=1 python finetune.py --config-dir=. --config-name=finetune_after_dagger_robocasa.yaml training.seed=42 task.name='CoffeePressButton' finetuning.dagger_episode_folder='dagger_episode_0' finetuning.human_only=True finetuning.from_scratch=False


A. Retrain from Scratch
CUDA_VISIBLE_DEVICES=1 HYDRA_FULL_ERROR=1 python finetune.py --config-dir=. --config-name=finetune_after_dagger_robocasa.yaml training.seed=42 task.name='CoffeePressButton' finetuning.dagger_episode_folder='dagger_episode_0' finetuning.human_only=False finetuning.from_scratch=True

B. Finetune on Aggregated Data, all parameters updated
CUDA_VISIBLE_DEVICES=0 HYDRA_FULL_ERROR=1 python finetune.py --config-dir=. --config-name=finetune_after_dagger_robocasa.yaml training.seed=42 task.name='CoffeePressButton' finetuning.dagger_episode_folder='dagger_episode_0' finetuning.human_only=False finetuning.from_scratch=False


C. Finetune on Aggregated Data, Freeze Observation encoder
CUDA_VISIBLE_DEVICES=0 HYDRA_FULL_ERROR=1 python finetune.py --config-dir=. --config-name=finetune_after_dagger_robocasa.yaml training.seed=42 task.name='CoffeePressButton' finetuning.dagger_episode_folder='dagger_episode_0' finetuning.human_only=False finetuning.from_scratch=False finetuning.freeze_obs_encoder=True


SECTION 2. Finetuning with batch balancing, multiple datafiles
D. Finetune with Batch Balanced 25% old data, 75% new data
CUDA_VISIBLE_DEVICES=2 HYDRA_FULL_ERROR=1 python finetune.py --config-dir=. --config-name=finetune_batch_balancing_after_dagger_robocasa.yaml training.seed=42 task.name='CoffeePressButton' finetuning.dagger_episode_folder='dagger_episode_0' finetuning.old_sampling_freq=0.25 finetuning.new_sampling_freq=0.75 finetuning.from_scratch=False

E. Finetune with Batch Balanced 50% old data, 50% new data 
CUDA_VISIBLE_DEVICES=2 HYDRA_FULL_ERROR=1 python finetune.py --config-dir=. --config-name=finetune_batch_balancing_after_dagger_robocasa.yaml training.seed=42 task.name='CoffeePressButton' finetuning.dagger_episode_folder='dagger_episode_0' finetuning.old_sampling_freq=0.5 finetuning.new_sampling_freq=0.5 finetuning.from_scratch=False

F. Finetune with Batch Balanced 75% old data, 25% new data
CUDA_VISIBLE_DEVICES=0 HYDRA_FULL_ERROR=1 python finetune.py --config-dir=. --config-name=finetune_batch_balancing_after_dagger_robocasa.yaml training.seed=42 task.name='CoffeePressButton' finetuning.dagger_episode_folder='dagger_episode_0' finetuning.old_sampling_freq=0.75 finetuning.new_sampling_freq=0.25 finetuning.from_scratch=False


SECTION 3: LoRA Finetuning
G. LoRA Finetuning Noise Predictor with Frozen Obs Encoder
CUDA_VISIBLE_DEVICES=1 HYDRA_FULL_ERROR=1 python finetune.py --config-dir=. --config-name=finetune_lora_after_dagger_robocasa.yaml training.seed=42 task.name='CoffeePressButton' finetuning.dagger_episode_folder='dagger_episode_0' finetuning.apply_lora_on_obs_encoder=False finetuning.freeze_obs_encoder=True

H. LoRA Finetuning Noise Predictor with Finetuned Obs Encoder
CUDA_VISIBLE_DEVICES=0 HYDRA_FULL_ERROR=1 python finetune.py --config-dir=. --config-name=finetune_lora_after_dagger_robocasa.yaml training.seed=42 task.name='CoffeePressButton' finetuning.dagger_episode_folder='dagger_episode_0' finetuning.apply_lora_on_obs_encoder=True


D. Finetuning with Orthogonal Projection


E. Finetuning with DriftDAgger
I may skip this, because the rank scheduler is over multiple demos being added in one by one, I've only got one batch here.


10. Evaluate after finetuning
Section 1: Evaluating all but LoRA
CUDA_VISIBLE_DEVICES=1 python evaluate.py --config-name=evaluate_after_dagger_finetuning_robocasa dagger.ckpt_folder='finetune_w_human_onlyTrue_from_base_after_dagger' task_name='CoffeePressButton' dagger.ckpt_name='latest'
CUDA_VISIBLE_DEVICES=1 python evaluate.py --config-name=evaluate_after_dagger_finetuning_robocasa dagger.ckpt_folder='finetune_w_human_onlyTrue_from_base_after_dagger' task_name='CoffeePressButton' dagger.ckpt_name='epoch_250_step_13972'

Section 2: Evaluating LoRA Models specifically
CUDA_VISIBLE_DEVICES=1 python evaluate.py --config-name=evaluate_lora_finetuning_robocasa dagger.ckpt_folder='finetune_w_human_onlyTrue_from_base_after_dagger' task_name='CoffeePressButton' dagger.ckpt_name='epoch_250_step_13972'



























